<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <link href="css/screen-sideways-stats.css" rel="stylesheet">
    <title>Important Insignificance</title>
    <meta name="author" content="Michael J. Freeman">
    <meta name="description" content="Using sideways stats to understand statistics.">
    <link rel="icon" sizes="16x16 24x24 32x32 48x48 64x64" href="../css/gfx/favicon.ico" type="image/x-icon">
    <link rel="icon" sizes="192x192" href="../css/gfx/favicon-192x192.png" type="image/png">
    <link rel="icon" sizes="152x152" href="../css/gfx/favicon-152x152.png" type="image/png">
    <link rel="icon" sizes="120x120" href="../css/gfx/favicon-120x120.png" type="image/png">
    <link rel="shortcut icon" href="../css/gfx/favicon.ico" type="image/x-icon" />
    <link href='http://fonts.googleapis.com/css?family=Merriweather+Sans:700,700italic,300,300italic&subset=latin' rel='stylesheet' type='text/css'>
    <script src="css/modernizr.custom.30817.js"></script>
  </head>
  <body>
    <main>
      <h1>Important Insignificance</h1>
      <h2>An example of understanding statistics by looking at them sideways</h2>
      <article>
        <p>
          When is an insignificant result important? When you check for the wrong significance.
        </p>
        <p>
          (Note: The discussion on this page employs visual aids I'm calling “sideways statistics”. They're explained on the page of the same name, <a href="sideways-stats.html"><i>Sideways Statistics</i></a>.)
        </p>
        <div class="w1008">
          <img src="images/large/basic-alpha-beta-es-n.svg" alt="Figure 01: Statistical experiment with alpha = 5% and statistical power = 84%" />
          <a href="images/basic-alpha-beta-es-n.html"><img class="button" src="images/full-screen-button.svg" alt="Show full size" /></a>
          <p>Figure 01</p>
        </div>
        <p>
          Say you're about to run an linear regression. You've already determined the expected size of effect, you've set the significance bar at an alpha of 0.05, and with those two you've determined the sample size to give you a statistical power of 0.84. Figure 01 shows your statistical experiment as designed.
        </p>
        <p>
          The minimum correlation that is statistically significant is marked by the line that bisects the population probability curve on the right side of the graphic. Since you set alpha to 0.05, 5% of the area bounded by the population probability curve extends below the null line.
        </p>
        <p>
          That's all the same in the next graphic, Figure 02, but the arrow is pointing to the line that marks the results of your analysis. It has failed to be large enough to qualify as statistically significant.
        </p>
        <div class="w1008-l">
          <img src="images/large/alpha-beta-es-n-with-result.svg" alt="Figure 02: Statistical experiment with “insignificant” result" />
          <a href="images/alpha-beta-es-n-with-result.html"><img class="button" src="images/full-screen-button.svg" alt="Show full size" /></a>
          <p>Figure 02</p>
        </div>
        <p>
          Most people would assume that the analysis was a bust and that without a statistically significant correlation, you can't really say anything definitive about the results. But that isn't true.
        </p>
        <p>
          Let's move on to Figure 03, in which the minimum statistically significant correlation has been removed, so that now the curve on the right side of the graphics is the population probability curve that's centered on the <strong>result</strong> from your hypothetical analysis. That result is not “statistically significant” at ‘p&lt;.05’ because more than 5% of the area between that curve and the vertical baseline is below the horizontal null line.
        </p>
        <p>
          But that's going on at the bottom of the population probability curve. Let's consider the top of that curve, where there's been a new line added to the graph, one that's marked with an arrow. Below that line is 95% of the area between the population probability curve and the vertical baseline. Which means you can say, with a confidence of ‘p&lt;.05’, that the population correlation is <em>no higher than that line</em>.
        </p>
        <div class="w1008">
          <img src="images/large/insignificant-result.svg" alt="Figure 03: Reconsidering the results of a statistical experiment" />
          <a href="images/insignificant-result.html"><img class="button" src="images/full-screen-button.svg" alt="Show full size" /></a>
          <p>Figure 03</p>
        </div>
        <p>
          Therefore, another way to look at the results of your analysis is to say that you have found a statistically significant “upper bound” for the population correlation. Whether or not that is a useful thing to know depends on what real-world phenomena your data is tracking.
        </p>
        <p>
          So, for example, if your data is tracking the effectiveness of some new investment strategy by correlating its implementation to the change in overall returns, it might be fairly straight-forward to determine the minimum impact required to make it worthwhile to use the new strategy. Whatever correlation matches to that impact becomes the minimum correlation that supports using the new strategy.
        </p>
        <p>
          In a scenario such as that, a null-hypothesis significance test would likely be useless to you. If it wasn't readily apparent—or at least highly probable—that the new strategy would improve outcomes, no one would even be trying. That there will be an improvement is something of a foregone conclusion; what matters is the degree of the improvement. And what matters to you is the confidence with which you can state that the correlation you find through your analysis is either higher or lower than the minimum correlation that supports using that new strategy.
        </p>
        <p>
          If we combine this hypothetical scenario with the hypothetical results from earlier, we can say that it doesn't matter that the resulting correlation didn't achieve statistical significance compared to null. What matters in this case is whether or not the upper bound we found is lower than the minimum correlation that supports using the new procedure. Because if it is, we can say with a confidence of ‘p&lt;.05’ that the new strategy isn't worth implementing. Even though we can't say (with the same confidence) that the correlation isn't significantly different than zero.
        </p>
      </article>
      <article>
        <h2>Testing for an upper bound</h2>
        <p>
          What would it look like if we designed our experiment from the beginning to check for an upper bound, such as described in the previous section? That is, let's test to see if we can say, with 95% confidence, that a correlation is lower than some value that we interpret as the minimum <b>important</b> correlation?
        </p>
        <div class="w1008-l">
          <img src="images/large/upper-bound-test.svg" alt="Figure 04: Statistical experiment to check upper bound" />
          <a href="images/upper-bound-test.html"><img class="button" src="images/full-screen-button.svg" alt="Show full size" /></a>
          <p>Figure 04</p>
        </div>
        <p>
          Instead of the sample probability curve on the left side of the graph being centered around the expected effect size, it would be centered around the value that's the minimum important correlation. Then, the population probability curve on the right side of the graph would be positioned so that 95% of the area between it and the vertical baseline would be below the minimum important correlation. The line that bisects the population probability curve is therefore the maximum correlation that demonstrates that the correlation does not meet your criteria for importance. See Figure 04.
        </p>
        <p>
          The shaded area on the left side of the graph are all the population correlations that are lower than the minimum important correlation. The shaded area on the right side is 5% of the area between the population correlation curve and the vertical baseline. Since that shaded area is 0.05 of the total, the line bisecting the that curve marks the <em>maximum</em> sample correlation at which you can say, with ‘p&lt;.05’, that the population correlation is unimportant.
        </p>
        <p>
          This sort of analysis is simply an application of established methods for testing the difference between two hypothesis, neither of which is zero (a.k.a., null). Such analyses are referred to as [NAME]? Check your preferred reference for how to actually crunch the numbers (e.g., [CITE…]).
        </p>
      </article>
      <article>
        <h2>Type I & II errors</h2> 
        <div class="w1008">
          <img src="images/large/upper-bound-type-I-error.svg" alt="Figure 05: Type I error in an upper bound test" />
          <a href="images/upper-bound-type-I-error.html"><img class="button" src="images/full-screen-button.svg" alt="Show full size" /></a>
          <p>Figure 05</p>
        </div>
        <p>
          The visual interpretation of Type I and Type II errors for this type of analysis differs from that for a null-hypothesis significance test.  For a Type I error in a null-hypothesis significance test, the population is assumed to have a correlation of zero, and for a Type II error, the population is assumed to be equal to the correlation predicted in the estimate of effect size.  For an upper-bound type of test, there are no specific correlations to assume for the determination of error.  Rather, a worst-case-scenario is used.  For both error types, the worst-case is a population correlation that is almost exactly equal to the correlation selected as the lower boundary of importance.  In a Type I error, the worst-case population correlation is infinitesimally higher than the importance cut-off; in a Type II error, the worst-case population correlation is infinitesimally lower than the importance cut-off.
        </p>
        <p>
          Type I errors are false positives.  In this case, that means that you would identify a population correlation as being below the minimum important correlation, when in fact it's equal to or above that minimum.  Figure 05 shows a population correlation that is infinitesimally higher than the minimum important correlation.  The line that bisects the population probability curve is the maximum correlation that would meet your hypothesis that the correlation is not important.  So, the area below that line, and between the sample probability curve and the vertical baseline, is equal to the worst-case probability of getting an apparently unimportant sample correlation for a population that, in fact, has an important correlation.
        </p>
        <div class="w1008-l">
          <img src="images/large/upper-bound-type-II-error.svg" alt="Figure 06: Type II error in an upper bound test" />
          <a href="images/upper-bound-type-II-error.html"><img class="button" src="images/full-screen-button.svg" alt="Show full size" /></a>
          <p>Figure 06</p>
        </div>
        <p>
          Much like with the null-hypothesis significance test, we know that the area that covers the Type I error is 5%, since it is symmetric with the area that's between the population probability curve and the vertical baseline, and also above  the value chosen as the minimum important population correlation.  The sample population curve was positioned vertical such that the area above the minimum important correlation was 5% of the total, giving the analysis ‘p<.05’.  Both the 5% areas are shaded in Figure 05.
        </p>
        <p>
          Type II errors are false negatives.  In this case that means you would fail to properly identify a population correlation as being below the minimum important correlation.  Figure 06 shows a population correlation that is infinitesimally lower than the minimum important correlation.  Any sample correlation that is higher than the maximum correlation that is significantly below the importance cut-off will lead to a Type II error.  The population does have an unimportant correlation, but the sample analysis fails to identify it.
        </p>
      </article>
    </main>
    <footer>
      <meta name="creator" content="不爽老男人">
    </footer>
    <script>
      if (!Modernizr.svg) {
          var imgs = document.getElementsByTagName('img');
          var svgExtension = /.*\.svg$/
          var l = imgs.length;
          for(var i = 0; i < l; i++) {
              if(imgs[i].src.match(svgExtension)) {
                  imgs[i].src = imgs[i].src.slice(0, -3) + 'png';
                  console.log(imgs[i].src);
              }
          }
      }
      function setDisplay (targetEID,targetDisplay) {
        var targetElement = document.getElementById(targetEID);
        targetElement.style.display = ( targetElement.style.display = targetDisplay );
      }
    </script>
  </body>
</html>
